{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, shutil\n",
    "\n",
    "#Creating the necessary directories for copying images to training, validation and test directories\n",
    "original_dataset_dir = '/home/joel/DL_Python/Dogs_vs_Cats_Dataset/train'\n",
    "\n",
    "base_dir = '/home/joel/DL_Python/Dogs_vs_Cats_Dataset_small'\n",
    "#os.mkdir(base_dir)\n",
    "\n",
    "train_dir = os.path.join(base_dir, 'train')\n",
    "#os.mkdir(train_dir)\n",
    "validation_dir = os.path.join(base_dir, 'validation')\n",
    "#os.mkdir(validation_dir)\n",
    "test_dir = os.path.join(base_dir, 'test')\n",
    "#os.mkdir(test_dir)\n",
    "\n",
    "train_cats_dir = os.path.join(train_dir, 'cats')\n",
    "#os.mkdir(train_cats_dir)\n",
    "\n",
    "train_dogs_dir = os.path.join(train_dir, 'dogs')\n",
    "#os.mkdir(train_dogs_dir)\n",
    "\n",
    "validation_cats_dir = os.path.join(validation_dir, 'cats')\n",
    "#os.mkdir(validation_cats_dir)\n",
    "\n",
    "validation_dogs_dir = os.path.join(validation_dir, 'dogs')\n",
    "#os.mkdir(validation_dogs_dir)\n",
    "\n",
    "\n",
    "test_cats_dir = os.path.join(test_dir, 'cats')\n",
    "#os.mkdir(test_cats_dir)\n",
    "\n",
    "test_dogs_dir = os.path.join(test_dir, 'dogs')\n",
    "#os.mkdir(test_dogs_dir)\n",
    "\n",
    "#Copying the first 1000 cat images to train_cats_dir\n",
    "fnames = ['cat.{}.jpg'.format(i) for i in range(1000)]\n",
    "for fname in fnames:\n",
    "    src = os.path.join(original_dataset_dir, fname)\n",
    "    dst = os.path.join(train_cats_dir, fname)\n",
    "    shutil.copyfile(src, dst)\n",
    "\n",
    "#Copying the next 500 cat images to validation_cats_dir\n",
    "fnames = ['cat.{}.jpg'.format(i) for i in range(1000,1500)]\n",
    "for fname in fnames:\n",
    "    src = os.path.join(original_dataset_dir, fname)\n",
    "    dst = os.path.join(validation_cats_dir, fname)\n",
    "    shutil.copyfile(src, dst)\n",
    "\n",
    "#Copying the next 500 cat images to test_cats_dir\n",
    "fnames = ['cat.{}.jpg'.format(i) for i in range(1500,2000)]\n",
    "for fname in fnames:\n",
    "    src = os.path.join(original_dataset_dir, fname)\n",
    "    dst = os.path.join(test_cats_dir, fname)\n",
    "    shutil.copyfile(src, dst)\n",
    "    \n",
    "#Copying the first 1000 dog images to train_dogs_dir\n",
    "fnames = ['dog.{}.jpg'.format(i) for i in range(1000)]\n",
    "for fname in fnames:\n",
    "    src = os.path.join(original_dataset_dir, fname)\n",
    "    dst = os.path.join(train_dogs_dir, fname)\n",
    "    shutil.copyfile(src, dst)\n",
    "    \n",
    "#Copying the next 500 dog images to validation_dogs_dir\n",
    "fnames = ['dog.{}.jpg'.format(i) for i in range(1000,1500)]\n",
    "for fname in fnames:\n",
    "    src = os.path.join(original_dataset_dir, fname)\n",
    "    dst = os.path.join(validation_dogs_dir, fname)\n",
    "    shutil.copyfile(src, dst)\n",
    "    \n",
    "#Copying the next 500 dog images to test_dogs_dir\n",
    "fnames = ['dog.{}.jpg'.format(i) for i in range(1500,2000)]\n",
    "for fname in fnames:\n",
    "    src = os.path.join(original_dataset_dir, fname)\n",
    "    dst = os.path.join(test_dogs_dir, fname)\n",
    "    shutil.copyfile(src, dst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import models\n",
    "\n",
    "#Building the model\n",
    "model = models.Sequential()\n",
    "model.add(layers.Conv2D(32, (3,3), activation = 'relu', input_shape = (150, 150, 3)))\n",
    "model.add(layers.MaxPooling2D((2,2)))\n",
    "model.add(layers.Conv2D(64, (3,3), activation = 'relu'))\n",
    "model.add(layers.MaxPooling2D((2,2)))\n",
    "model.add(layers.Conv2D(128, (3,3), activation = 'relu'))\n",
    "model.add(layers.MaxPooling2D((2,2)))\n",
    "model.add(layers.Conv2D(128, (3,3), activation = 'relu'))\n",
    "model.add(layers.MaxPooling2D((2,2)))\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(512, activation = 'relu'))\n",
    "model.add(layers.Dense(1, activation = 'sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_12 (Conv2D)           (None, 148, 148, 32)      896       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_12 (MaxPooling (None, 74, 74, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_13 (Conv2D)           (None, 72, 72, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_13 (MaxPooling (None, 36, 36, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_14 (Conv2D)           (None, 34, 34, 128)       73856     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_14 (MaxPooling (None, 17, 17, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_15 (Conv2D)           (None, 15, 15, 128)       147584    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_15 (MaxPooling (None, 7, 7, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten_3 (Flatten)          (None, 6272)              0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 512)               3211776   \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 1)                 513       \n",
      "=================================================================\n",
      "Total params: 3,453,121\n",
      "Trainable params: 3,453,121\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import optimizers\n",
    "model.compile(loss='binary_crossentropy', optimizer = optimizers.RMSprop(lr=1e-4), metrics = ['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2000 images belonging to 2 classes.\n",
      "Found 1000 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "#Using ImageDataGenerator to read images from directories\n",
    "#Rescaling all images bi 1/255\n",
    "train_datagen = ImageDataGenerator(rescale=1./255)\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(train_dir, target_size=(150,150),\n",
    "                                                    batch_size=20, class_mode='binary')\n",
    "validation_generator = test_datagen.flow_from_directory(validation_dir, target_size=(150,150),\n",
    "                                                        batch_size=29, class_mode='binary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data batch shape: (20, 150, 150, 3)\n",
      "Labels batch shape: (20,)\n"
     ]
    }
   ],
   "source": [
    "#Printing the shape of the reshaped images\n",
    "for data_batch, labels_batch in train_generator:\n",
    "    print('Data batch shape:', data_batch.shape)\n",
    "    print('Labels batch shape:', labels_batch.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "100/100 [==============================] - 85s 849ms/step - loss: 0.6939 - acc: 0.5390 - val_loss: 0.6806 - val_acc: 0.6021\n",
      "Epoch 2/30\n",
      "100/100 [==============================] - 105s 1s/step - loss: 0.6618 - acc: 0.6075 - val_loss: 0.6659 - val_acc: 0.5763\n",
      "Epoch 3/30\n",
      "100/100 [==============================] - 113s 1s/step - loss: 0.6110 - acc: 0.6615 - val_loss: 0.6436 - val_acc: 0.6160\n",
      "Epoch 4/30\n",
      "100/100 [==============================] - 90s 896ms/step - loss: 0.5713 - acc: 0.6965 - val_loss: 0.7073 - val_acc: 0.5979\n",
      "Epoch 5/30\n",
      "100/100 [==============================] - 115s 1s/step - loss: 0.5354 - acc: 0.7305 - val_loss: 0.6053 - val_acc: 0.6578\n",
      "Epoch 6/30\n",
      "100/100 [==============================] - 114s 1s/step - loss: 0.5077 - acc: 0.7570 - val_loss: 0.5714 - val_acc: 0.6829\n",
      "Epoch 7/30\n",
      "100/100 [==============================] - 114s 1s/step - loss: 0.4732 - acc: 0.7660 - val_loss: 0.5711 - val_acc: 0.6962\n",
      "Epoch 8/30\n",
      "100/100 [==============================] - 108s 1s/step - loss: 0.4461 - acc: 0.8000 - val_loss: 0.5532 - val_acc: 0.7213\n",
      "Epoch 9/30\n",
      "100/100 [==============================] - 77s 769ms/step - loss: 0.4177 - acc: 0.8120 - val_loss: 0.6000 - val_acc: 0.6941\n",
      "Epoch 10/30\n",
      "100/100 [==============================] - 77s 775ms/step - loss: 0.3904 - acc: 0.8225 - val_loss: 0.5746 - val_acc: 0.7164\n",
      "Epoch 11/30\n",
      "100/100 [==============================] - 114s 1s/step - loss: 0.3689 - acc: 0.8335 - val_loss: 0.5603 - val_acc: 0.7261\n",
      "Epoch 12/30\n",
      "100/100 [==============================] - 110s 1s/step - loss: 0.3398 - acc: 0.8485 - val_loss: 0.5705 - val_acc: 0.7192\n",
      "Epoch 13/30\n",
      "100/100 [==============================] - 105s 1s/step - loss: 0.3023 - acc: 0.8730 - val_loss: 0.6172 - val_acc: 0.7017\n",
      "Epoch 14/30\n",
      "100/100 [==============================] - 112s 1s/step - loss: 0.2864 - acc: 0.8780 - val_loss: 0.6094 - val_acc: 0.7129\n",
      "Epoch 15/30\n",
      "100/100 [==============================] - 117s 1s/step - loss: 0.2663 - acc: 0.9000 - val_loss: 0.6213 - val_acc: 0.7150\n",
      "Epoch 16/30\n",
      "100/100 [==============================] - 77s 774ms/step - loss: 0.2431 - acc: 0.9065 - val_loss: 0.6166 - val_acc: 0.7345\n",
      "Epoch 17/30\n",
      "100/100 [==============================] - 87s 867ms/step - loss: 0.2186 - acc: 0.9190 - val_loss: 0.6098 - val_acc: 0.7345\n",
      "Epoch 18/30\n",
      "100/100 [==============================] - 102s 1s/step - loss: 0.1932 - acc: 0.9280 - val_loss: 0.6692 - val_acc: 0.7296\n",
      "Epoch 19/30\n",
      "100/100 [==============================] - 119s 1s/step - loss: 0.1800 - acc: 0.9320 - val_loss: 0.6532 - val_acc: 0.7213\n",
      "Epoch 20/30\n",
      "100/100 [==============================] - 80s 798ms/step - loss: 0.1575 - acc: 0.9370 - val_loss: 0.7079 - val_acc: 0.7150\n",
      "Epoch 21/30\n",
      "100/100 [==============================] - 79s 786ms/step - loss: 0.1360 - acc: 0.9575 - val_loss: 0.8029 - val_acc: 0.7031\n",
      "Epoch 22/30\n",
      "100/100 [==============================] - 81s 813ms/step - loss: 0.1108 - acc: 0.9690 - val_loss: 0.7980 - val_acc: 0.7150\n",
      "Epoch 23/30\n",
      "100/100 [==============================] - 78s 783ms/step - loss: 0.0952 - acc: 0.9725 - val_loss: 0.8277 - val_acc: 0.7220\n",
      "Epoch 24/30\n",
      "100/100 [==============================] - 78s 781ms/step - loss: 0.0856 - acc: 0.9760 - val_loss: 0.8185 - val_acc: 0.7394\n",
      "Epoch 25/30\n",
      "100/100 [==============================] - 78s 782ms/step - loss: 0.0751 - acc: 0.9785 - val_loss: 0.8531 - val_acc: 0.7073\n",
      "Epoch 26/30\n",
      "100/100 [==============================] - 78s 781ms/step - loss: 0.0647 - acc: 0.9805 - val_loss: 0.9728 - val_acc: 0.7101\n",
      "Epoch 27/30\n",
      "100/100 [==============================] - 76s 756ms/step - loss: 0.0492 - acc: 0.9890 - val_loss: 0.9419 - val_acc: 0.7296\n",
      "Epoch 28/30\n",
      "100/100 [==============================] - 76s 758ms/step - loss: 0.0424 - acc: 0.9930 - val_loss: 1.0024 - val_acc: 0.7233\n",
      "Epoch 29/30\n",
      "100/100 [==============================] - 76s 756ms/step - loss: 0.0361 - acc: 0.9935 - val_loss: 1.1296 - val_acc: 0.7380\n",
      "Epoch 30/30\n",
      "100/100 [==============================] - 76s 756ms/step - loss: 0.0353 - acc: 0.9915 - val_loss: 1.0416 - val_acc: 0.7324\n"
     ]
    }
   ],
   "source": [
    "#Fitting the model using a batch generator\n",
    "#Since the batch size is 20 and we have 2000 train images, we have 100 steps per epoch\n",
    "history = model.fit_generator(train_generator, steps_per_epoch=100, epochs=30,\n",
    "                              validation_data=validation_generator, validation_steps=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
